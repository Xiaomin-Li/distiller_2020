# time python3 compress_classifier.py --arch resnet20_cifar  ../../../data.cifar10 -p=50 --lr=0.3 --epochs=180 --compress=../agp-pruning/myyaml/resnet20_fg_4hy.yaml --resume-from=./logs/[resent20_cifar path] --reset-optimizer --vs=0 -n resnet20_hy_allinone_50spa

version: 1

pruners:

  fine_pruner:
    class:  AutomatedGradualPruner
    initial_sparsity : 0.05
    final_sparsity: 0.50
    weights: [
                module.layer1.0.conv1.weight,
                #module.layer1.0.conv2.weight,
                module.layer1.1.conv1.weight,
                #module.layer1.1.conv2.weight,
                module.layer1.2.conv1.weight,
                #module.layer1.2.conv2.weight,
                module.layer2.0.conv1.weight,
                module.layer2.0.conv2.weight,
                module.layer2.0.downsample.0.weight,
                module.layer2.1.conv1.weight,
                module.layer2.1.conv2.weight,
                module.layer2.2.conv1.weight,
                module.layer2.2.conv2.weight,
                #module.layer3.0.conv1.weight,
                module.layer3.0.downsample.0.weight,
                module.layer3.0.conv2.weight,
                #module.layer3.1.conv1.weight,
                module.layer3.1.conv2.weight,
                #module.layer3.2.conv1.weight,
                module.layer3.2.conv2.weight
              ]

  low_pruner_1:
    class: L1RankedStructureParameterPruner_AGP
    initial_sparsity : 0.10
    final_sparsity: 0.75
    group_type: Filters
    weights: [module.layer1.0.conv1.weight,
              module.layer1.1.conv1.weight,
              module.layer1.2.conv1.weight]

  low_pruner_2:
    class: L1RankedStructureParameterPruner_AGP
    initial_sparsity : 0.10
    final_sparsity: 0.75
    group_type: Filters
    weights: [module.layer2.0.conv1.weight, module.layer2.0.conv2.weight,
              module.layer2.0.downsample.0.weight,
              module.layer2.1.conv2.weight, module.layer2.2.conv2.weight,
              module.layer2.1.conv1.weight, module.layer2.2.conv1.weight]

  low_pruner_3:
    class: L1RankedStructureParameterPruner_AGP
    initial_sparsity : 0.10
    final_sparsity: 0.75
    group_type: Filters
    group_dependency: Leader
    weights: [module.layer3.0.conv2.weight, module.layer3.0.downsample.0.weight,
              module.layer3.1.conv2.weight,  module.layer3.2.conv2.weight]


  fc_pruner:
    class: L1RankedStructureParameterPruner_AGP
    initial_sparsity : 0.05
    final_sparsity: 0.75
    group_type: Rows
    weights: [module.fc.weight]


lr_schedulers:
  pruning_lr:
    class: StepLR
    step_size: 50
    gamma: 0.10


policies:
  - pruner:
      instance_name : fine_pruner
    starting_epoch: 0
    ending_epoch: 30
    frequency: 2

  - pruner:
      instance_name : low_pruner_1
    starting_epoch: 32
    ending_epoch: 62
    frequency: 2

  - pruner:
      instance_name : low_pruner_2
    starting_epoch: 32
    ending_epoch: 62
    frequency: 2

  - pruner:
      instance_name : low_pruner_3
    starting_epoch: 32
    ending_epoch: 62
    frequency: 2

  - pruner:
      instance_name : fc_pruner
    starting_epoch: 32
    ending_epoch: 62
    frequency: 2


  # Currently the thinner is disabled until the the structure pruner is done, because it interacts
  # with the sparsity goals of the L1RankedStructureParameterPruner_AGP.
  # This can be fixed rather easily.
  # - extension:
  #     instance_name: net_thinner
  #   starting_epoch: 0
  #   ending_epoch: 20
  #   frequency: 2

# After completing the pruning, we perform network thinning and continue fine-tuning.

  - lr_scheduler:
      instance_name: pruning_lr
    starting_epoch: 0
    ending_epoch: 400
    frequency: 1
